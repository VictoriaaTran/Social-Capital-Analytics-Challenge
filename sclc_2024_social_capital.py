# -*- coding: utf-8 -*-
"""SCLC 2024: Social Capital

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14GcZlHjxb-X5abZCzWvyjb9703DK7Ewe

#Data Cleaning

- export and read files
- drop rows with missing values
"""

import pandas as pd

#read csv files
college = pd.read_csv('social_capital_college.csv')
county = pd.read_csv('social_capital_county.csv')

#drop rows with missing values of specific columns (cluster, support, volunteer, and civic, exposure, parent)
county = county.dropna(subset=['clustering_county',
                               'support_ratio_county',
                               'volunteering_rate_county',
                               'civic_organizations_county'])
college = college.dropna(subset=['clustering_college',
                                 'support_ratio_college',
                                 'volunteering_rate_college'
                                 ])

#drop specific columns, keeping first 4 columns
# county = county.iloc[:, :4]

#merge the dataset based on county
merge_college = pd.merge(county, college, on='county')
merge_college.to_csv('collegeOut.csv')

#drop rows that have missing values
merge_college = merge_college.dropna(subset=['ec_own_ses_college',
                                             'exposure_own_ses_college',
                                             'exposure_parent_ses_college',
                                             'bias_own_ses_college'
                                             ])

"""#Data Analysis
- simple descriptive analysis that calculate the average values that are associated with economic connectedness

*Note: this analysis is working with colleges based on county
"""

# average the clustering score for college
clustering_college_total = 0
clustering_college_avg = 0
count_college = 0
for val in merge_college['clustering_college']:
  count_college += 1
  clustering_college_total += val
clustering_college_avg = clustering_college_total / count_college
print(f'Average clustering for college: {clustering_college_avg}')

# average the support ratio for college
support_college_total = 0
support_college_avg = 0
count_sup_college = 0
for val in merge_college['support_ratio_college']:
  count_sup_college += 1
  support_college_total += val
support_college_avg = support_college_total / count_sup_college
print(f'Average support ratio for college: {support_college_avg}')

# average the volunteer rate for college
volunteer_college_total = 0
volunteer_college_avg = 0
count_vol_college = 0
for val in merge_college['volunteering_rate_college']:
  count_vol_college += 1
  volunteer_college_total += val
volunteer_college_avg = volunteer_college_total / count_vol_college
print(f'Average volunteer rate for college: {volunteer_college_avg}')

# average the parent ses for college
parent_college_total = 0
parent_college_avg = 0
count_parent_college = 0
for val in merge_college['ec_parent_ses_college']:
  count_parent_college += 1
  parent_college_total += val
parent_college_avg = parent_college_total / count_parent_college
print(f'\nAverage parent connectedness for college: {parent_college_avg}')

# average parent exposure ses for college
parentEx_college_total = 0
parentEx_college_avg = 0
count_parentEx_college = 0
for val in merge_college['exposure_parent_ses_college']:
  count_parentEx_college += 1
  parentEx_college_total += val
parentEx_college_avg = parentEx_college_total / count_parentEx_college
print(f'Average parent exposure for college: {parentEx_college_avg}')


# average for high SES parent for college
highP_college_total = 0
highP_college_avg = 0
count_highP_college = 0
for val in merge_college['ec_high_parent_ses_college']:
  count_highP_college += 1
  highP_college_total += val
highP_college_avg = highP_college_total / count_highP_college
print(f'Average high SES parent for college: {highP_college_avg}')

"""##Data Modeling
- train the model and apply linear regression

selecting independent and dependent variable for college dataset
"""

from sklearn.model_selection import train_test_split
from sklearn import linear_model

#select the predictors (independent var)
independent_college = ['ec_parent_ses_college',
                       'exposure_parent_ses_college',
                       'clustering_college',
                       'volunteering_rate_college',
                       'support_ratio_college',
                       'bias_own_ses_college',
                       ]

x_college = merge_college[independent_college]

#select the dependent variable
dependent_college = ['ec_own_ses_college']
y_college = merge_college[dependent_college]

#split the train and test with 7:3 ratio
x_college_train, x_college_test, y_college_train, y_college_test = train_test_split(x_college, y_college, train_size=0.3)

# build the linear regression for college
regressor_college = linear_model.LinearRegression()
regressor_college.fit(x_college_train, y_college_train)

"""Predict the test set"""

college_predict = regressor_college.predict(x_college_test)
college_predict

"""Evaluate the error and goodness of the linear model"""

from sklearn import metrics

# measure the MSE
MSE_college = metrics.mean_squared_error(y_college_test, college_predict)
print('MSE for college: ', MSE_college)

# measure MAE
MAE_college = metrics.mean_absolute_error(y_college_test, college_predict)
print('MAE for college: ', MAE_college)

# measure the goodness/fit of the model
R_sq_college = metrics.r2_score(y_college_test, college_predict)
print('R^2 for college: ', R_sq_college)

"""View the summary statistics of the regression model includes coefficient and significant level (p-value)"""

import statsmodels.api as sm

# add constant variables for intercept
college_sum = sm.add_constant(x_college)
college_model = sm.OLS(y_college, college_sum).fit()

#obtain the summary of the model
print(college_model.summary())

"""Pearson Model analysis"""

import pandas as pd
from scipy.stats import pearsonr

# Assuming x_college_train and y_college_train are your training sets
# Concatenate the training sets into one DataFrame
train_data = pd.concat([x_college_train, y_college_train], axis=1)

# Calculate Pearson correlation coefficients and p-values
correlation_summary = []

for predictor_col in x_college_train.columns:
    correlation_coefficient, p_value = pearsonr(train_data[predictor_col], train_data[y_college.columns[0]])
    correlation_summary.append({
        'Variable': predictor_col,
        'Pearson Correlation': correlation_coefficient,
        'P-value': f'{p_value:.4f}'
    })

# Convert the list of dictionaries to a DataFrame
correlation_summary_df = pd.DataFrame(correlation_summary)

# Display the summary statistics
print(correlation_summary_df)

"""#Data Summary
- finding the sum Economic Connectedness score for colleges by state
- finding other useful insights about colleges among the states and individual counties
"""

# calculate average connectedness for colleges by state

college_ec = {}
num_state = 0
college_count = {}  # to keep track of the number of colleges for each state

for index, row in merge_college.iterrows():
  county_name = row['county_name']
  ec_val = row['ec_own_ses_college'] # EC value from colleges
  state = county_name.split(',')
  state = [x.strip(' ') for x in state] #remove empty spaces
  state = state[1]

  if state in college_ec:
    college_ec[state] += ec_val
    college_count[state].add(row['college_name'])

  else:
    college_ec[state] = ec_val
    num_state += 1
    college_count[state] = {row['college_name']}  # Initialize a set with the first college


print(f'There are total of {num_state} states in the dataset.')
# print(f'Economic Connectedness from colleges by states (A-Z):')
# for key, value in states_ec.items():
#   print(f'{key}: {value:.3f}')

#sort the dictionary from high to low
sorted_ec = dict(sorted(college_ec.items(), key=lambda x: x[1], reverse=True))
print(f'\nTop 5 colleges by state with HIGHEST CONNECTEDNESS (SUM):')
for key, value in list(sorted_ec.items())[:5]:
    print(f'{key}: {value}')

print(f'\nTop 5 colleges by state with the LOWEST CONNECTEDNESS(SUM):')
for key, value in list(sorted_ec.items())[-5:]:
    print(f'{key}: {value}')

# print(states_ec)

# calculate average for each state
for state, total_ec in college_ec.items():
  # print(total_ec)
  # print(college_count[state])
  college_ec[state] = total_ec / len(college_count[state])

sorted_avg_ec = dict(sorted(college_ec.items(), key=lambda x: x[1], reverse=True))
# print the average EC score for each state
print('\nAverage Economic Connectedness from colleges by state:')
for state, avg_ec in list(sorted_avg_ec.items()):
  print(f'{state}: {avg_ec:.3f}')

# print(sorted_ec)

"""Calculate population by state"""

# newData_college.to_csv('newData.csv')
#drop the duplicates by county name
newData_college = merge_college.drop_duplicates(subset=['county_name'])

#drop state that has missing value on population
newData_college = newData_college.dropna(subset=['pop2018'])

#calculate population by each state
state = ''
state_pop = {}
for index, row in newData_college.iterrows():
  pop = row['pop2018']
  county_name = row['county_name']
  state = county_name.split(',')
  state = [x.strip(' ') for x in state] #remove empty spaces
  state = state[1]
  if state in state_pop:
    if pop == None:
      pop = 0
    else:
      state_pop[state] += pop
  else:
    state_pop[state] = pop

#sort the dataset by population
sorted_state_pop = dict(sorted(state_pop.items(), key=lambda x: x[1], reverse=True))

print(f'\nTop 5 states with the HIGHEST POPULATION:')
for key, value in list(sorted_state_pop.items())[:5]:
  print(f'{key}: {value:.0f}')

print(f'\nTop 5 states with the LOWEST POPULATION:')
for key, value in list(sorted_state_pop.items())[-5:]:
  print(f'{key}: {value:.0f}')

# drop missing values on ec_county
newData_college = newData_college.dropna(subset=['ec_county'])


#calculate
county_ec = {}
count = 0
county_ec_avg = 0
for index, row in newData_college.iterrows():
  county_name = row['county_name']
  ec_val = row['ec_county'] # EC value from states
  state = county_name.split(',')
  state = state[1].strip() #extract state name and remove empty spaces
  if state in county_ec:
    county_ec[state]['count'] += 1
    county_ec[state]['total_ec'] += ec_val
  else:
    county_ec[state] = {'count': 1, 'total_ec': ec_val}

# calculate avg and add average score to state
for state, values in county_ec.items():
  if values['count'] != 0:
    values['county_ec_avg'] = values['total_ec'] / values['count']

print(county_ec)

#sorted by average score
sorted_counties = sorted(county_ec.items(), key=lambda x: x[1]['county_ec_avg'], reverse=True)

print('\nTotal EC by state (high to low):')
for state, values in sorted_counties:
    # avg_ec = values['county_ec_avg']
    count = values['count']
    total_ec = values['total_ec']
    avg = values['county_ec_avg']
    print(f'{state}: {avg}')

north_east = ['Connecticut',
              'Maine',
              'Massachusetts',
              'New Hampshire',
              'Rhode Island',
              'Vermont',
              'New Jersey',
              'New York',
              'Pennsylvania']
mid_west = ['Illinois',
            'Indiana',
            'Michigan',
            'Ohio',
            'Wisconsin',
            'Iowa',
            'Kansas',
            'Minnesota',
            'Missouri',
            'Nebraska',
            'North Dakota',
            'South Dakota']
south = ['Delaware',
         'Florida',
         'Georgia',
         'Maryland',
         'North Carolina',
         'South Carolina',
         'Virginia',
         'District of Columbia',
         'West Virginia',
         'Alabama',
         'Kentucky',
         'Mississippi',
         'Tennessee',
         'Arkansas',
         'Louisiana',
         'Oklahoma',
         'Texas']
west = ['Arizona',
        'Colorado',
        'Idaho',
        'Montana',
        'Nevada',
        'New Mexico',
        'Utah',
        'Wyoming',
        'Alaska',
        'California',
        'Hawaii',
        'Oregon',
        'Washington']

# grouping states into the 4 regions
region = ["northeast", 'west', 'south', 'midwest']
regions_data = [north_east,west,south,mid_west]

dict_region = {}
for i, reg in enumerate(region):
  temp = {}
  for s in regions_data[i]:
    temp[s] = college_ec[s]
  dict_region[reg]= temp

for key, value in dict_region.items():
  print(f'{key}: {value}')

# calculate average economic connectedness for each region
print('\nAVERAGE ECONOMIC CONNECTEDNESS FROM COLLEGES BY REGION')
for reg_key, reg_value in dict_region.items():
  reg_total = 0
  for state_key, state_value in reg_value.items():
    reg_total += state_value

  reg_avg = reg_total/len(reg_value)

  print(f'\n{reg_key}: {reg_avg}')
  print(f'Total number of states for region {reg_key} {len(reg_value)}')